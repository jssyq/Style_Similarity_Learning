# -*- coding: utf-8 -*-
"""Style-categorization-with-human-data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L1Eg_49Y2W35TpBQOC68nJyodLl9SOfi
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import warnings
import gdown
import glob
import cv2
import os
from matplotlib import pyplot

warnings.filterwarnings("ignore")

from google.colab import drive
drive.mount('/content/drive')

task_imgs = ["training_imgs/acne-1.png", "training_imgs/alberta-1.png", "training_imgs/3-1-phillip-lim-1.png", "training_imgs/alessandra-rich-1.png",
                "training_imgs/balmain-1.png", "training_imgs/altuzarra-1.png", "training_imgs/bottega-1.png", "training_imgs/ann-demeulemeester-1.png",
                "training_imgs/burberry-1.png", "training_imgs/attico-1.png", "training_imgs/carolina-herrera-1.png", "training_imgs/bally-1.png",
                "training_imgs/blumarine-1.png", "training_imgs/chanel-1.png", "training_imgs/brandon-maxwell-1.png", "training_imgs/chloe-1.png",
                "training_imgs/bronx-and-banco-1.png", "training_imgs/christian-dior-1.png", "training_imgs/carven-1.png", "training_imgs/coach-1.png",
                "training_imgs/casablanca-1.png", "training_imgs/diesel-1.png", "training_imgs/cecilie-bahnsen-1.png", "training_imgs/dolce-gabbana-1.png",
                "training_imgs/coperni-1.png", "training_imgs/dsquared-1.png", "training_imgs/courreges-1.png", "training_imgs/elie-saab-1.png",
                "training_imgs/david-koma-1.png", "training_imgs/emporio-armani-1.png", "training_imgs/dion-lee-1.png", "training_imgs/etro-1.png",
                "training_imgs/dries-van-noten-1.png", "training_imgs/fendi-1.png", "training_imgs/erdem-1.png", "training_imgs/giambattista-valli-1.png",
                "training_imgs/ermanno-scervino-1.png", "training_imgs/giorgio-armani-1.png", "training_imgs/ferrari-1.png", "training_imgs/gcds-1.png",
                "training_imgs/givenchy-1.png", "training_imgs/gabriela-hearst-1.png", "training_imgs/hermes-1.png", "training_imgs/heliot-emil-1.png",
                "training_imgs/isabel-marant-1.png", "training_imgs/j-w-anderson-1.png", "training_imgs/kenzo-1.png", "training_imgs/sandy-liang-1.png",
                "training_imgs/loewe-1.png", "training_imgs/laquan-smith-1.png", "training_imgs/louis-vuitton-1.png", "training_imgs/loveshackfancy-1.png",
                "training_imgs/maison-martin-margiela-1.png", "training_imgs/missoni-1.png", "training_imgs/marni-1.png", "training_imgs/mm6-1.png",
                "training_imgs/msgm-1.png", "training_imgs/max-mara-1.png", "training_imgs/naeem-khan-1.png", "training_imgs/mcqueen-1.png",
                "training_imgs/nina-ricci-1.png", "training_imgs/michael-kors-1.png", "training_imgs/no-21-1.png", "training_imgs/miu-miu-1.png",
                "training_imgs/paco-rabanne-1.png", "training_imgs/moschino-1.png", "training_imgs/peter-do-1.png", "training_imgs/mugler-1.png",
                "training_imgs/philipp-plein-1.png", "training_imgs/prada-1.png", "training_imgs/philosophy-1.png", "training_imgs/ralph-lauren-1.png",
                "training_imgs/prabal-gurung-1.png", "training_imgs/rick-owens-1.png", "training_imgs/proenza-schouler-1.png", "training_imgs/roberto-cavalli-1.png",
                "training_imgs/rachel-comey-1.png", "training_imgs/saint-laurent-1.png", "training_imgs/sacai-1.png", "training_imgs/simone-rocha-1.png",
                "training_imgs/salvatore-ferragamo-1.png", "training_imgs/staud-1.png", "training_imgs/schiaparelli-1.png", "training_imgs/theory-1.png",
                "training_imgs/tibi-1.png", "training_imgs/stella-mccartney-1.png", "training_imgs/ulla-johnson-1.png", "training_imgs/undercover-1.png",
                "training_imgs/tods-1.png", "training_imgs/y-project-1.png", "training_imgs/tom-ford-1.png", "training_imgs/yohji-yamamoto-1.png",
                "training_imgs/tory-burch-1.png", "training_imgs/valentino-1.png", "training_imgs/versace-1.png", "training_imgs/victoria-beckham-1.png",
                "training_imgs/zimmermann-1.png"]

imgs_labeled_names = []
imgs_unlabeled_names = []

import zipfile



with zipfile.ZipFile('/content/drive/My Drive/thesis/training_imgs.zip', 'r') as zip_ref:
    for file in zip_ref.namelist():
        name = file.replace("training_imgs/", "")
        name = name.replace("__MACOSX/._", "")
        # Check condition to determine the output directory
        if file in task_imgs:
            output_directory = '/imgs_with_labels'
            imgs_labeled_names.append(name)
        else:
            output_directory = '/imgs_no_labels'
            imgs_unlabeled_names.append(name)

        if not os.path.exists(output_directory):
            os.makedirs(output_directory)

        zip_ref.extract(file, output_directory)

imgs_unlabeled_names = sorted(list(set(imgs_unlabeled_names)))

imgs_labeled_names = sorted(list(set(imgs_labeled_names)))

imgs_unlabeled_names = [item for item in imgs_unlabeled_names if item not in imgs_labeled_names]

imgs_unlabeled_names = imgs_unlabeled_names[2:]

for i in range(len(imgs_labeled_names)):
  imgs_labeled_names[i] = imgs_labeled_names[i].replace("-1.png", "")

for i in range(len(imgs_unlabeled_names)):
  imgs_unlabeled_names[i] = imgs_unlabeled_names[i].replace(".png", "")

len(imgs_unlabeled_names)

"""# **Create training data**

"""

imgs_labeled = sorted(glob.glob('/imgs_with_labels/training_imgs/*.png'))
imgs_unlabeled = sorted(glob.glob('/imgs_no_labels/training_imgs/*.png'))

len(imgs_unlabeled)

print("Available GPU devices: ", tf.config.list_physical_devices('GPU'))

x_data = np.empty((len(imgs_labeled), 640, 248, 3), dtype=np.uint8)
x_test = np.empty((len(imgs_unlabeled), 640, 248, 3), dtype=np.uint8)

for i, img in enumerate(imgs_labeled):
    outfit_img = cv2.imread(img, cv2.IMREAD_UNCHANGED)
    if outfit_img is None:
      print(f"Error: Unable to load the image at the path {img}. Check the file path and permissions.")
      continue
    else:
      outfit_img = cv2.cvtColor(outfit_img, cv2.COLOR_BGRA2RGBA)
      alpha_channel = outfit_img[:, :, 3]
      alpha_channel = alpha_channel.astype(float) / 255.0
      alpha_channel_3d = np.stack((alpha_channel,) * 3, axis=-1)
      color_channels = outfit_img[:, :, :3]

      height, width = color_channels.shape[:2]
      background = np.ones((height, width, 3), dtype=np.uint8) * 255

      foreground = cv2.multiply(alpha_channel_3d, color_channels.astype(float))
      background = cv2.multiply(1.0 - alpha_channel_3d, background.astype(float))
      blended = cv2.add(foreground, background).astype(np.uint8)
      blended = cv2.resize(blended, (248, 640))
      x_data[i] = blended

for i, img in enumerate(imgs_unlabeled):
    outfit_img = cv2.imread(img, cv2.IMREAD_UNCHANGED)
    if outfit_img is None:
      print(f"Error: Unable to load the image at the path {img}. Check the file path and permissions.")
      continue
    else:
      outfit_img = cv2.cvtColor(outfit_img, cv2.COLOR_BGRA2RGBA)
      alpha_channel = outfit_img[:, :, 3]
      alpha_channel = alpha_channel.astype(float) / 255.0
      alpha_channel_3d = np.stack((alpha_channel,) * 3, axis=-1)
      color_channels = outfit_img[:, :, :3]

      height, width = color_channels.shape[:2]
      background = np.ones((height, width, 3), dtype=np.uint8) * 255

      foreground = cv2.multiply(alpha_channel_3d, color_channels.astype(float))
      background = cv2.multiply(1.0 - alpha_channel_3d, background.astype(float))
      blended = cv2.add(foreground, background).astype(np.uint8)
      blended = cv2.resize(blended, (248, 640))
      x_test[i] = blended

"""# **Import ResNet50**"""

ResNet50 = tf.keras.applications.ResNet50(
    include_top = False,
    weights="imagenet",
    input_shape = (640, 248, 3),
    pooling = "avg"
)

ResNet50.summary()

"""# **Use ResNet50 to extract features for input A and input B**"""

import keras

def euclidean_distance(vects):
    """Find the Euclidean distance between two vectors.

    Arguments:
        vects: List containing two tensors of same length.

    Returns:
        Tensor containing euclidean distance
        (as floating point value) between vectors.
    """

    x, y = vects
    difference = tf.square(x - y)
    sum_square = tf.reduce_sum(difference, axis=-1, keepdims=True)
    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))

input_A = keras.layers.Input(shape=(640, 248, 3), name="input_A")
input_B = keras.layers.Input(shape=(640, 248, 3), name="input_B")

features_A = ResNet50(input_A)
features_B = ResNet50(input_B)

distance_A_B = keras.layers.Lambda(euclidean_distance, output_shape=(1,))([features_A, features_B])

normalized_layer = keras.layers.BatchNormalization()(distance_A_B)
output = keras.layers.Dense(1, activation="sigmoid")(normalized_layer)

siamese = keras.Model(inputs=[input_A, input_B], outputs=output)

siamese.summary()

"""# **Prepare images pairs and labels**




"""

x_data.shape

imgs_labeled_names_1 = np.repeat(imgs_labeled_names, 96)

imgs_labeled_names_2 = np.tile(imgs_labeled_names, 96)

file_id = "19bnHkMIH1KcTEVAjN1k8wBvBVye-8c5Q"
url = f'https://drive.google.com/uc?id={file_id}'
distance_matrix = pd.read_csv(url,index_col=0)

distance_matrix

x_data = np.array(x_data)

x_train_a = []
x_train_b = []
y_train = []
train_pairs = []

for i in np.arange(len(imgs_labeled_names_1)):
  row = imgs_labeled_names_1[i]
  col = imgs_labeled_names_2[i]
  pair = sorted([row, col])

  if pair in train_pairs:
    continue
  else:
    distance = distance_matrix.at[row, col]
    y_train.append(distance)
    index_1 = imgs_labeled_names.index(row)
    index_2 = imgs_labeled_names.index(col)
    img_1 = x_data[index_1]
    img_2 = x_data[index_2]
    train_pairs.append(pair)
    x_train_a.append(img_1)
    x_train_b.append(img_2)

fig, axes = pyplot.subplots(1, 2, figsize=(10, 10))

axes[0].imshow(x_train_a[2406])
axes[1].imshow(x_train_b[2406])
print(y_train[2406])

def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))

siamese.compile(
    optimizer = 'adam',
    loss = rmse,
    metrics = ['mean_squared_error']
)

"""# **Train the Siamese Model**"""

batches = []

for i in range(0, len(x_train_a), 4):
    # Convert the current batch to a NumPy array
    batch = np.array(x_train_a[i:i+4], dtype=np.float16)
    batches.append(batch)

x_train_a_array = np.concatenate(batches)

batches_2 = []

for i in range(0, len(x_train_b), 4):
    # Convert the current batch to a NumPy array
    batch = np.array(x_train_b[i:i+4], dtype=np.float16)
    batches_2.append(batch)

x_train_b_array = np.concatenate(batches_2)

y_train = np.array(y_train, dtype=np.float16)

y_train.shape

x_train_a_preprocessed = tf.keras.applications.resnet.preprocess_input(x_train_a_array)

x_train_a_val = x_train_a_preprocessed[3000:]
x_train_a_learn = x_train_a_preprocessed[:3000]

x_train_b_preprocessed = tf.keras.applications.resnet.preprocess_input(x_train_b_array)

x_train_b_val = x_train_a_preprocessed[3000:]
x_train_b_learn = x_train_a_preprocessed[:3000]

y_train_learn = y_train[:3000]
y_train_val = y_train[3000:]

y_train_learn.shape

siamese.fit(
    [x_train_a_learn, x_train_b_learn], y_train_learn,
    validation_data=([x_train_a_val, x_train_b_val], y_train_val),
    epochs = 1,
    batch_size = 24
)

siamese.save('siamese_trained.keras')

siamese.fit(
    [x_train_a_learn, x_train_b_learn], y_train_learn,
    validation_data=([x_train_a_val, x_train_b_val], y_train_val),
    epochs = 1,
    batch_size = 24
)

siamese.fit(
    [x_train_a_learn, x_train_b_learn], y_train_learn,
    validation_data=([x_train_a_val, x_train_b_val], y_train_val),
    epochs = 1,
    batch_size = 24
)

siamese.save('siamese_trained_ep_3.keras')